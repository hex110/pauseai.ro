{
    "meta": {
        "title": "Riscurile IA | PauseAI România",
        "description": "Înțelege riscurile dezvoltării necontrolate a inteligenței artificiale, de la riscuri existențiale până la impactul asupra societății.",
        "keywords": "riscuri IA, inteligență artificială, risc existențial, siguranță IA, superinteligență, România"
    },
    "hero": {
        "title": "Riscurile Inteligenței Artificiale",
        "subtitle": "De ce trebuie să acționăm acum pentru un viitor sigur"
    },
    "intro": {
        "title": "Experții Trag un Semnal de Alarmă",
        "content": "Cercetătorii în IA estimează că există o șansă de 14% ca dezvoltarea unei superinteligențe artificiale să ducă la 'rezultate foarte negative (ex: extincția umană)'. Această estimare vine de la experții care lucrează direct în domeniu.",
        "quote": {
            "text": "Atenuarea riscului de extincție din cauza IA ar trebui să fie o prioritate globală, alături de alte riscuri la scară societală, precum pandemiile și războiul nuclear.",
            "source": "Declarația privind riscurile IA, semnată de sute de experți și cercetători"
        }
    },
    "mainRisks": [
        {
            "title": "Risc Existențial",
            "content": "Sistemele IA superinteligente ar putea reprezenta un risc existențial pentru umanitate dacă nu sunt dezvoltate cu măsuri de siguranță adecvate. Acest risc nu este unul teoretic - mulți experți, inclusiv pionieri ai domeniului precum Geoffrey Hinton și Yoshua Bengio, avertizează asupra acestui pericol.",
            "stats": {
                "percentage": "30%",
                "description": "Șansa medie estimată de experții în siguranța IA pentru scenariul extincției umane"
            }
        },
        {
            "title": "Pierderea Controlului",
            "content": "Un sistem IA superinteligent ar putea deveni imposibil de controlat odată dezvoltat. Având acces la internet, un astfel de sistem ar putea manipula infrastructura digitală, dezvolta tehnologii periculoase sau influența societatea în moduri imprevizibile.",
            "warning": "Nu putem presupune că vom putea 'deconecta' un sistem IA superinteligent odată ce acesta devine operațional."
        },
        {
            "title": "Impact Social și Economic",
            "content": "Dezvoltarea rapidă a IA poate destabiliza societatea prin:\n- Amplificarea dezinformării și manipulării\n- Perturbarea piețelor financiare\n- Automatizarea masivă a locurilor de muncă\n- Creșterea inegalităților sociale\n- Erodarea proceselor democratice"
        }
    ],
    "urgency": {
        "title": "De Ce Trebuie să Acționăm Acum",
        "points": [
            {
                "title": "Progres Rapid",
                "content": "În 2020, experții estimau că IA va putea trece examenele universitare până în 2050. Acest obiectiv a fost atins în martie 2023 de către GPT-4."
            },
            {
                "title": "Competiție Periculoasă",
                "content": "Companiile de IA sunt prinse într-o cursă periculoasă pentru dezvoltarea sistemelor tot mai avansate, sacrificând siguranța pentru avantaj competitiv."
            },
            {
                "title": "Lipsa Soluțiilor",
                "content": "Nu avem încă soluții pentru problema alinierii IA cu valorile umane. Companiile precum OpenAI și Anthropic recunosc deschis acest lucru."
            }
        ]
    },
    "expertQuotes": [
        {
            "quote": "Nu am întâlnit nimeni în laboratoarele de IA care să spună că riscul este mai mic de 1% de a distruge planeta.",
            "author": "Jaan Tallinn",
            "title": "Co-fondator Skype și Future of Life Institute"
        },
        {
            "quote": "Mă aștept ca o entitate mai inteligentă și indiferentă să găsească strategii și tehnologii care ne pot ucide rapid și sigur.",
            "author": "Eliezer Yudkowsky",
            "title": "Co-fondator Machine Intelligence Research Institute"
        }
    ],
    "callToAction": {
        "title": "Ce Putem Face?",
        "content": "Pentru toate problemele discutate mai sus, riscul crește pe măsură ce capabilitățile IA se îmbunătățesc. Cel mai sigur lucru de făcut acum este să încetinim dezvoltarea sistemelor IA mai puternice până când înțelegem cum să gestionăm riscurile.",
        "button": "Implică-te în Mișcare"
    }
} 